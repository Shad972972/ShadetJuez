shad_d42l
shad_d42l
Invisible

shad_d42l ‚Äî 09/02/2025 21:52
vasy tkt
juezhd ‚Äî 11/02/2025 22:54
viens discord y'a moha il veut de parler
juezhd ‚Äî 26/03/2025 15:19
juezhd ‚Äî 29/03/2025 00:00
https://link.chess.com/play/LlxmsG
Jouez aux √©checs avec TheJuez !
Cliquez sur ce lien pour commencer une partie d‚Äô√©checs avec TheJuez
Image
juezhd ‚Äî 03/04/2025 04:05
https://store.steampowered.com/app/3417410/Storebound/
Steam
Storebound
A co-op survival horror game. Play as 1 of 4 ordinary shoppers who wake up in an endless store. Find the exit together at all costs before the "employees" catch you.

Escape Alone or With Friends 
Trapped inside a nightmarish store, you play as ordinary shoppers desperately looking for an exit.

‚Ä¶
Release Date
Coming soon
shad_d42l ‚Äî 03/04/2025 23:59
frero
tu viens jouer ?
juezhd ‚Äî 04/04/2025 00:00
vasy j'arrive
shad_d42l ‚Äî 06/04/2025 14:10
viens jouer
juezhd ‚Äî 07/04/2025 19:29
JVQPF-TYH72-3PDX6-WMFT6-39M3Z
juezhd ‚Äî 07/04/2025 20:32
t'es la ?
juezhd ‚Äî 08/04/2025 20:25
viens
shad_d42l ‚Äî 08/04/2025 21:33
envoi un message si ca murky jregarde ma serie
juezhd ‚Äî 29/04/2025 17:52
https://www.youtube.com/watch?v=HCV6nEACQo4&t
YouTube
CodeAvecJonathan
WEB SCRAPING PYTHON [TUTO PROGRAMMATION COMPLET] (D√âBUTANT √Ä AVAN...
Image
shad_d42l ‚Äî 30/04/2025 10:50
tes la le s
juezhd ‚Äî 30/04/2025 13:38
c'est comment
shad_d42l ‚Äî 30/04/2025 13:39
tu veux avancer sur le scrapping ?
juezhd ‚Äî 30/04/2025 13:39
ui
shad_d42l ‚Äî 30/04/2025 13:39
azi viens en dessous
juezhd ‚Äî 30/04/2025 13:39
la je regarde une vid√©o pour savoir comment utilis√© bright data
shad_d42l ‚Äî 02/05/2025 03:00
tetais pas la aujourdhui
juezhd ‚Äî 02/05/2025 10:16
ouais excuse jme suis reveiller tard je suis reparti dormir
juezhd ‚Äî 02/05/2025 16:49
https://tzofzbtc.genspark.space/
juezhd ‚Äî 02/05/2025 17:51
sdd
import os
import zipfile
import time
import urllib.request
import ssl
from selenium import webdriver
Afficher plus
scriptBASE.py
4 Ko
juezhd ‚Äî 02/05/2025 20:10
ta reussi le make.com ?
shad_d42l ‚Äî 02/05/2025 20:12
non le s , ya plusieur maniere de faire des requete de 30 second, dis toi on est pas obliger de passer par make , mais si on lutilise a tout prix , jai besoin de toi pour rajouter des ligne de code au fichier de scrap
juezhd ‚Äî 02/05/2025 20:12
rajouter quoi ?
shad_d42l ‚Äî 02/05/2025 20:12
un requirement txt
juezhd ‚Äî 02/05/2025 20:13
pour installer les bibliotheque python ?
shad_d42l ‚Äî 02/05/2025 20:13
oui ca sappelle flask
juezhd ‚Äî 02/05/2025 20:13
bah tu fais juste pip install flask nan ?
shad_d42l ‚Äî 02/05/2025 20:14
je peux appeller ?
juezhd ‚Äî 02/05/2025 20:15
att dans 5 minutes
juezhd
 a commenc√© un appel qui a dur√© 26 minutes. ‚Äî 02/05/2025 20:53
juezhd ‚Äî 02/05/2025 21:03
import os
import zipfile
import time
import urllib.request
import ssl
import json
Afficher plus
message.txt
11 Ko
juezhd ‚Äî 02/05/2025 23:58
s
import os
import zipfile
import time # Assurez-vous que l'import time est pr√©sent
import urllib.request
import ssl
import json
Afficher plus
vinted2.py
12 Ko
juezhd ‚Äî 03/05/2025 16:19
https://www.reddit.com/r/SaaS/?rdt=34865
Reddit
r/SaaS
Discussions and useful links for SaaS owners, online business owners, and more.
Image
juezhd ‚Äî 03/05/2025 20:02
{
        "image": "",
        "price": "",
        "name": ""
    },
juezhd ‚Äî 03/05/2025 20:30
t'es la ?
shad_d42l ‚Äî 03/05/2025 20:30
5min
juezhd ‚Äî 03/05/2025 20:30
azy
juezhd ‚Äî 03/05/2025 21:33
git commit -m "Votre message d√©crivant les modifications"
git push origin main
juezhd ‚Äî 04/05/2025 20:40
snipefinder
shad_d42l ‚Äî 05/05/2025 17:50
https://dashboard.render.com/web/srv-d0b5g51r0fns73d5gt90/deploys/dep-d0b71lhr0fns73d6vfgg?r=2025-05-03%4019%3A38%3A03~2025-05-03%4019%3A41%3A38
Cloud Application Hosting for Developers | Render
Cloud Application Hosting for Developers | Render
Render is a unified cloud to build and run all your apps and websites with free SSL, global CDN, private networks and automatic deploys from Git.
Cloud Application Hosting for Developers | Render
https://shadetjuez.onrender.com/
shad_d42l ‚Äî Hier √† 14:37
dis moi quand tes la
juezhd ‚Äî 13:33
https://storage.googleapis.com/chrome-for-testing-public/136.0.7103.92/win64/chromedriver-win64.zip
shad_d42l ‚Äî 13:43
==> Deploying...
575k6
==> Running 'python vinted2.py'
575k6
Cr√©ation de l'extension proxy...
575k6
Lancement de Chrome avec proxy pour Vinted...
575k6
Une erreur majeure est survenue pendant le processus de scraping : Message: 'chromedriver.exe' executable may have wrong permissions.
575k6
575k6
Le navigateur n'a pas pu √™tre initialis√©.
575k6
==> Running 'python vinted2.py'
575k6
Cr√©ation de l'extension proxy...
575k6
Lancement de Chrome avec proxy pour Vinted...
575k6
Une erreur majeure est survenue pendant le processus de scraping : Message: 'chromedriver.exe' executable may have wrong permissions.
575k6
575k6
Le navigateur n'a pas pu √™tre initialis√©.
     ==> No open ports detected, continuing to scan...
     ==> Docs on specifying a port: https://render.com/docs/web-services#port-binding
575k6
==> Running 'python vinted2.py'
575k6
Cr√©ation de l'extension proxy...
575k6
Lancement de Chrome avec proxy pour Vinted...
575k6
Une erreur majeure est survenue pendant le processus de scraping : Message: 'chromedriver.exe' executable may have wrong permissions.
575k6
575k6
Le navigateur n'a pas pu √™tre initialis√©.
575k6
==> Running 'python vinted2.py'
575k6
Cr√©ation de l'extension proxy...
575k6
Lancement de Chrome avec proxy pour Vinted...
575k6
Une erreur majeure est survenue pendant le processus de scraping : Message: 'chromedriver.exe' executable may have wrong permissions.
575k6
575k6
Le navigateur n'a pas pu √™tre initialis√©.
Render
Web Services
Deploy Web Services on Render in just a few clicks.
Web Services
juezhd ‚Äî 13:48
chmod +x chromedriver && python vinted2.py 
https://storage.googleapis.com/chrome-for-testing-public/136.0.7103.92/linux64/chromedriver-linux64.zip
juezhd ‚Äî 14:08
# Naviguer vers le dossier de votre projet
cd /chemin/vers/votre/dossier/projet

# Mettre √† jour votre d√©p√¥t local avec les derni√®res modifications de GitHub (IMPORTANT avant de modifier/supprimer)
git pull origin <nom_de_votre_branche>
# Exemple : git pull origin main
Afficher plus
supprimer fichier git up tuto.txt
2 Ko
import os
import zipfile
import time # Assurez-vous que l'import time est pr√©sent
import urllib.request
import ssl
import json
Afficher plus
message.txt
12 Ko
shad_d42l ‚Äî 14:17
==> Cloning from https://github.com/Shad972972/ShadetJuez
==> Checking out commit 7f8cc4d2f323a47a75506b52d0c1578a24f03e6e in branch main
==> Downloading cache...
==> Transferred 71MB in 7s. Extraction took 1s.
==> Using Python version 3.11.11 (default)
==> Docs on specifying a Python version: https://render.com/docs/python-version
==> Using Poetry version 1.7.1 (default)
==> Docs on specifying a Poetry version: https://render.com/docs/poetry-version
==> Running build command 'python vinted2.py '...
Traceback (most recent call last):
  File "/opt/render/project/src/vinted2.py", line 8, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
==> Build failed üòû
==> Common ways to troubleshoot your deploy: https://render.com/docs/troubleshooting-deploys
GitHub
GitHub - Shad972972/ShadetJuez
Contribute to Shad972972/ShadetJuez development by creating an account on GitHub.
Contribute to Shad972972/ShadetJuez development by creating an account on GitHub.
Render
Setting Your Python Version
Use a specific version of Python for your Render service.
Setting Your Python Version
Render
Setting Your Poetry Version
Use a specific version of Poetry for your Render service.
Setting Your Poetry Version
Render
Troubleshooting Your Deploy
Diagnose and resolve common issues when deploying to Render.
Troubleshooting Your Deploy
juezhd ‚Äî 14:22
pip install -r requirements.txt
chmod +x ./chromedriver && python vinted2.py
juezhd ‚Äî 14:37
s
import os
import zipfile
import time
import urllib.request
import ssl
import json
Afficher plus
message.txt
12 Ko
Ôªø
import os
import zipfile
import time
import urllib.request
import ssl
import json

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException, TimeoutException

# --- Import ajout√© pour webdriver-manager ---
from webdriver_manager.chrome import ChromeDriverManager

# --- Param√®tres Proxy ---
proxy_host = 'brd.superproxy.io'
proxy_port = 33335
proxy_user = 'brd-customer-hl_6f4c5bd7-zone-datacenter1'
proxy_pass = 'v5ttvuka2n0x'

# --- Param√®tres Vinted ---
VINTED_URL = "https://www.vinted.fr/catalog/1242-trainers"
OUTPUT_FILE = "vinted_elements_global_pages.json"
MAX_PAGES = 10

# --- Cr√©er l'extension proxy ---
def create_proxy_extension():
    manifest_json = """
    {
        "version": "1.0.0",
        "manifest_version": 2,
        "name": "Chrome Proxy",
        "permissions": [
            "proxy",
            "tabs",
            "unlimitedStorage",
            "storage",
            "<all_urls>",
            "webRequest",
            "webRequestBlocking"
        ],
        "background": {
            "scripts": ["background.js"]
        },
        "minimum_chrome_version":"22.0.0"
    }
    """

    background_js = f"""
    var config = {{
            mode: "fixed_servers",
            rules: {{
              singleProxy: {{
                scheme: "http",
                host: "{proxy_host}",
                port: parseInt({proxy_port})
              }},
              bypassList: ["localhost"]
            }}
          }};

    chrome.proxy.settings.set({{value: config, scope: "regular"}}, function() {{}});

    chrome.webRequest.onAuthRequired.addListener(
        function(details) {{
            return {{
                authCredentials: {{
                    username: "{proxy_user}",
                    password: "{proxy_pass}"
                }}
            }};
        }},
        {{urls: ["<all_urls>"]}},
        ['blocking']
    );
    """

    pluginfile = 'proxy_auth_plugin.zip'

    with zipfile.ZipFile(pluginfile, 'w') as zp:
        zp.writestr("manifest.json", manifest_json)
        zp.writestr("background.js", background_js)

    return pluginfile

# --- Fonction de Scraping Vinted (M√©thode globale avec pagination) ---
def scrape_vinted_global_elements_with_proxy_pagination():
    print("Cr√©ation de l'extension proxy...")
    pluginfile = create_proxy_extension()

    chrome_options = Options()
    chrome_options.add_extension(pluginfile)
    # --- Options Headless d√©comment√©es pour Render ---
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    # --- Fin des options Headless ---
    chrome_options.add_argument("--start-maximized") # Utile en mode non headless

    # --- Code de gestion manuelle de chromedriver supprim√©/comment√© ---
    # driver_path = os.path.join(os.getcwd(), 'chromedriver')
    # if not os.path.exists(driver_path):
    #     print(f"Erreur : chromedriver non trouv√© √† l'emplacement : {driver_path}")
    #     print("Veuillez t√©l√©charger le chromedriver correspondant √† votre version de Chrome et le placer au m√™me endroit que le script.")
    #     return
    # service = Service(driver_path)
    # --- Fin du code supprim√©/comment√© ---


    print("Lancement de Chrome avec proxy pour Vinted...")
    driver = None
    # Liste globale pour stocker les articles de toutes les pages
    all_sneaker_items = []

    try:
        # --- Initialisation du Service via ChromeDriverManager ---
        print("Utilisation de webdriver-manager pour obtenir chromedriver...")
        service = Service(ChromeDriverManager().install())
        # --- Fin de l'initialisation ---

        driver = webdriver.Chrome(service=service, options=chrome_options)

        # --- Boucle sur les pages ---
        for page_num in range(1, MAX_PAGES + 1):
            print(f"\n--- Scraping de la page {page_num} ---")

            # Construire l'URL pour la page courante
            if page_num == 1:
                page_url = VINTED_URL
            else:
                # Ajoute &page=X. V√©rifie si l'URL contient d√©j√† des param√®tres (?)
                if '?' in VINTED_URL:
                    page_url = f"{VINTED_URL}&page={page_num}"
                else:
                    # Si l'URL de base n'a pas de ?, ajoute ?page=X
                    page_url = f"{VINTED_URL}?page={page_num}"

            print(f"Ouverture de la page : {page_url}")
            driver.get(page_url)

            # --- G√©rer les popups de cookies ou autres sur chaque page (peut appara√Ætre √† nouveau) ---
            try:
                WebDriverWait(driver, 5).until( # Temps d'attente r√©duit pour le popup sur les pages suivantes
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid="cookie-banner"]'))
                )
                # Essayer de trouver et cliquer sur le bouton d'acceptation principal
                accept_button = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.web_ui__Button__primary'))
                )
                accept_button.click()
                print("Popup de cookies g√©r√© sur cette page.")
                WebDriverWait(driver, 5).until_not(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid="cookie-banner"]'))
                )
            except (NoSuchElementException, TimeoutException):
                pass # Ignorer silencieusement si pas de popup
            except Exception as e:
                 print(f"Erreur lors de la gestion du popup sur la page {page_num} : {e}")


            # --- Extraction des donn√©es pour la page courante (M√©thode globale) ---

            # Attendre la pr√©sence d'au moins UN des types d'√©l√©ments que l'on cherche
            print("Attente du chargement des √©l√©ments (images) sur la page courante...")
            try:
                # On attend plus longtemps pour le chargement initial des √©l√©ments sur chaque page
                WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'div.new-item-box__image img'))
                )
                print("√âl√©ments (images) d√©tect√©s sur la page courante.")
            except TimeoutException:
                print(f"Erreur : Timeout en attendant la pr√©sence des √©l√©ments images sur la page {page_num}. Passage √† la page suivante.")
                continue # Passer √† la prochaine it√©ration de la boucle (prochaine page)


            # Trouver TOUS les √©l√©ments correspondant aux classes sp√©cifi√©es sur toute la page courante
            print("Extraction des √©l√©ments par classe sur la page courante...")
            image_elements = driver.find_elements(By.CSS_SELECTOR, 'div.new-item-box__image img')
            description_elements = driver.find_elements(By.CSS_SELECTOR, 'div.new-item-box__description')
            price_elements = driver.find_elements(By.CSS_SELECTOR, 'span.web_ui__Text__text.web_ui__Text__subtitle.web_ui__Text__left.web_ui__Text__clickable.web_ui__Text__underline-none')

            print(f"Images trouv√©es : {len(image_elements)}")
            print(f"Descriptions trouv√©es : {len(description_elements)}")
            print(f"Prix trouv√©s : {len(price_elements)}")

            # D√©terminer le nombre minimum d'√©l√©ments trouv√©s pour √©viter les erreurs d'index
            min_elements = min(len(image_elements), len(description_elements), len(price_elements))

            if min_elements == 0:
                print(f"Aucun des √©l√©ments cl√©s n'a √©t√© trouv√© sur la page {page_num}.")
            else:
                print(f"Association et ajout de {min_elements} articles trouv√©s sur la page {page_num}...")
                # Parcourir jusqu'au minimum trouv√© et associer les donn√©es par index
                for i in range(min_elements):
                    item_data = {}
                    try:
                        # Extraire l'image (src ou data-src)
                        img_elem = image_elements[i]
                        item_data['image'] = img_elem.get_attribute('src') if img_elem.get_attribute('src') else img_elem.get_attribute('data-src')

                        # Extraire le prix (texte)
                        price_elem = price_elements[i]
                        item_data['price'] = price_elem.text.strip()

                        # Extraire la description (texte)
                        desc_elem = description_elements[i]
                        item_data['name'] = desc_elem.text.strip()

                        # L'URL ne peut pas √™tre associ√©e de mani√®re fiable avec cette m√©thode globale.
                        # item_data['url'] = None

                        # Ajouter l'article extrait √† la liste globale
                        all_sneaker_items.append(item_data)

                    except IndexError:
                        print(f"Erreur d'index inattendue √† l'√©l√©ment {i} sur la page {page_num}.")
                        break # Arr√™ter l'association pour cette page
                    except Exception as e:
                        print(f"Erreur inattendue lors du traitement de l'√©l√©ment {i} sur la page {page_num} : {e}. √âl√©ment ignor√©.")
                        continue


            # --- D√©lai entre les pages ---
            if page_num < MAX_PAGES: # Pas besoin d'attendre apr√®s la derni√®re page
                 sleep_time = 2 # D√©lai en secondes
                 print(f"Attente de {sleep_time} secondes avant la page suivante...")
                 time.sleep(sleep_time)


        # --- Fin de la boucle sur les pages ---
        print(f"\n--- Scraping termin√©. Total des articles collect√©s sur {MAX_PAGES} pages : {len(all_sneaker_items)} ---")


        # --- Sauvegarde des donn√©es (apr√®s avoir scrap√© toutes les pages) ---
        if all_sneaker_items:
            try:
                with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                    json.dump(all_sneaker_items, f, indent=4, ensure_ascii=False)

                print(f"Donn√©es de tous les articles extraits sauvegard√©es dans {OUTPUT_FILE}")
            except IOError as e:
                print(f"Erreur lors de l'√©criture du fichier {OUTPUT_FILE} : {e}")
        else:
            print("Aucun article n'a pu √™tre extrait sur toutes les pages. Fichier de sortie non cr√©√©.")

    except Exception as e:
        print(f"Une erreur majeure est survenue pendant le processus de scraping : {e}")

    finally:
        if driver:
            print("Fermeture du navigateur.")
            driver.quit()
        else:
            print("Le navigateur n'a pas pu √™tre initialis√©.")

# --- Point d'entr√©e du script ---
if __name__ == "__main__":
    scrape_vinted_global_elements_with_proxy_pagination()